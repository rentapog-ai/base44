name: Daily Error Report

on:
  schedule:
    - cron: "0 8 * * *"
  workflow_dispatch:
    inputs:
      hours:
        description: "Time range in hours to look back"
        required: false
        default: "24"
        type: string

jobs:
  report:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install PostHog CLI
        run: npm install -g @posthog/cli

      - name: Set time range
        id: time-range
        run: |
          HOURS="${{ inputs.hours || '24' }}"
          echo "hours=$HOURS" >> $GITHUB_OUTPUT

      - name: Query error summary
        env:
          POSTHOG_CLI_TOKEN: ${{ secrets.POSTHOG_CLI_API_KEY }}
          POSTHOG_CLI_ENV_ID: ${{ vars.POSTHOG_PROJECT_ID }}
        run: |
          posthog-cli exp query run "SELECT properties.is_user_error as is_user_error, properties.error_code as error_code, count() as occurrences, count(DISTINCT distinct_id) as users_affected, countIf(distinct_id LIKE '%@wix.com' OR distinct_id LIKE '%@base44.com') as internal_occurrences, any(properties.\$exception_values) as sample_message, any(properties.command_name) as sample_command FROM events WHERE event = '\$exception' AND timestamp >= now() - INTERVAL ${{ steps.time-range.outputs.hours }} HOUR GROUP BY is_user_error, error_code ORDER BY occurrences DESC" > /tmp/summary.jsonl || true

      - name: Query error details
        env:
          POSTHOG_CLI_TOKEN: ${{ secrets.POSTHOG_CLI_API_KEY }}
          POSTHOG_CLI_ENV_ID: ${{ vars.POSTHOG_PROJECT_ID }}
        run: |
          posthog-cli exp query run "SELECT properties.\$exception_fingerprint as fingerprint, count() as occurrences, any(properties.\$exception_types) as exception_type, any(properties.\$exception_values) as exception_message, substring(toString(any(properties.\$exception_list)), 1, 3000) as exception_list, any(properties.\$exception_level) as level, any(properties.error_code) as error_code, any(properties.is_user_error) as is_user_error, any(properties.command_name) as command_name, any(properties.cli_version) as cli_version, any(properties.node_version) as node_version, any(properties.platform) as platform, any(properties.arch) as arch, any(properties.os_type) as os_type, any(properties.is_agent) as is_agent, any(properties.agent_name) as agent_name, any(properties.api_status_code) as api_status_code, any(properties.api_request_url) as api_request_url, any(properties.api_request_method) as api_request_method, max(timestamp) as last_seen, min(timestamp) as first_seen FROM events WHERE event = '\$exception' AND timestamp >= now() - INTERVAL ${{ steps.time-range.outputs.hours }} HOUR GROUP BY fingerprint ORDER BY occurrences DESC LIMIT 25" > /tmp/details.jsonl || true

      - name: Trim output files
        run: |
          for f in /tmp/summary.jsonl /tmp/details.jsonl; do
            if [ -f "$f" ] && [ "$(wc -c < "$f")" -gt 200000 ]; then
              awk 'BEGIN{t=0}{t+=length($0)+1; if(t>200000) exit; print}' "$f" > "${f}.tmp" && mv "${f}.tmp" "$f"
            fi
          done

      - name: Check for errors
        id: check-errors
        run: |
          if [ -s /tmp/summary.jsonl ]; then
            echo "has_errors=true" >> $GITHUB_OUTPUT
          else
            echo "has_errors=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate report with Claude
        if: steps.check-errors.outputs.has_errors == 'true'
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          prompt: |
            You are an error triage engineer for the Base44 CLI (a TypeScript CLI tool built with Commander.js).
            Your task: analyze the error data from the last ${{ steps.time-range.outputs.hours }} hours and produce a GitHub issue report.

            ## Context

            PostHog project ID: `${{ vars.POSTHOG_PROJECT_ID }}`
            PostHog error tracking URL pattern: `https://us.posthog.com/project/${{ vars.POSTHOG_PROJECT_ID }}/error_tracking/<fingerprint>`

            ## Step 1: Read the error data

            Read two JSONL files (one JSON array per line):

            **`/tmp/summary.jsonl`** — aggregated error counts. Columns (by position):
            `[is_user_error, error_code, occurrences, users_affected, internal_occurrences, sample_message, sample_command]`
            - `users_affected` = unique users (count of distinct users, no PII)
            - `internal_occurrences` = how many occurrences came from internal users (@wix.com / @base44.com)

            **`/tmp/details.jsonl`** — one representative event per unique error group (grouped by fingerprint, ordered by occurrences DESC). Columns (by position):
            `[fingerprint, occurrences, exception_type, exception_message, exception_list, level, error_code, is_user_error, command_name, cli_version, node_version, platform, arch, os_type, is_agent, agent_name, api_status_code, api_request_url, api_request_method, last_seen, first_seen]`

            ## PRIVACY — this repo is public, the issue will be public

            The data does NOT contain user emails or distinct_ids. However, other fields may still leak PII:
            - **Stack traces** (`exception_list`): frame `filename` paths may contain usernames (e.g. `/Users/john/node_modules/...`). When including stack traces in the report, replace any home-directory path segments with `<redacted>` (e.g. `/Users/<redacted>/node_modules/base44/...`).
            - **Error messages** (`exception_message`): may contain file paths with usernames. Apply the same redaction.
            - **`app_id`**: this is an internal ID. You may use it for grouping/counting, but do NOT list raw app_id values in the report.
            - **`api_request_url`**: redact any query parameters and path segments that look like tokens or user-specific identifiers.
            - Never include user emails, names, IP addresses, or identifiable information in the report.

            ## Step 2: Check for recurring errors and existing issues

            Before analyzing, gather context:

            1. **Previous error reports**: Run `gh issue list --label error-report --limit 5 --json number,title,body,createdAt` to get the last few daily reports. Read through them to identify errors that keep recurring across multiple days. If an error appeared in previous reports too, mark it as **recurring** and note how many consecutive days it has appeared.

            2. **Existing GitHub issues**: For each unique error you find in the data, search for existing open issues that might already track it:
               - Run `gh issue list --state open --search "<error_code or key phrase from the error message>" --json number,title,labels,assignees --limit 5`
               - If you find a matching issue, link to it in the report instead of re-describing the problem. Note the issue number and whether someone is assigned.

            ## Step 3: Understand the errors — always include code snippets

            The details file is already grouped by fingerprint (one row per unique error group, ordered by occurrences). For each error group:
            1. Read the stack trace from `exception_list` (it's a JSON array of `{type, value, stacktrace: {frames: [{filename, lineno, colno, function}]}}`)
               Note: `exception_list` is truncated to ~3000 chars — this should include the most relevant top frames.
            2. **Include the error message and stack trace from PostHog** in the report. Show `exception_message` and the top 3-5 frames from `exception_list`. These are the actual errors users hit.
            3. **Build a PostHog link** for each error using the `fingerprint` field: `https://us.posthog.com/project/${{ vars.POSTHOG_PROJECT_ID }}/error_tracking/<fingerprint>`. Include this link in the report so readers can drill into PostHog for full details.
            4. Use the stack trace frames to find the relevant source files in this repository (under `src/`). Map the frame `filename` and `lineno` to actual source files using Grep/Glob.
            5. **Read those source files** and understand WHY the error happened. This is critical — you MUST read the actual source code, not guess.
            6. **Include code snippets** in the report for every error. Show the exact lines from `src/` that caused or are related to the error. Use the `// src/path/to/file.ts:NN` format.
            7. Check if the error is a known pattern or a real bug.

            Each error in the report must have BOTH: (a) the error/stack trace from PostHog data, and (b) the relevant source code from the repo.

            ## Step 4: Classify and filter

            - **System errors** (`is_user_error = false`): These are bugs. Always include them.
            - **User errors** (`is_user_error = true`): These are expected (auth expired, invalid input, etc). Only include a user error if:
              - It affects many different users (>= 5 from `users_affected`), suggesting a CLI problem rather than individual user mistakes
              - OR it looks like a CLI bug disguised as a user error
            - **Internal vs external**: Use `internal_occurrences` from the summary to note what fraction of errors come from internal users.

            ## Step 5: Create the GitHub issue

            If there are errors worth reporting, create ONE GitHub issue using `gh issue create`. The issue should follow this structure:

            **Title**: `Error Report: <date> (<N> errors in last <hours>h)`

            **Body** (use this template):

            ```
            ## Summary

            Brief 2-3 sentence overview of the error landscape. Mention total errors, how many are system vs user, and the most critical finding.

            ## Key Metrics

            | Metric | Value |
            | --- | --- |
            | Time range | last <hours> hours |
            | Total errors | N |
            | System errors | N |
            | User errors (noteworthy) | N |
            | Unique users affected | N |
            | Internal user occurrences | N |

            ## Recurring Errors

            If any errors appeared in previous daily reports, list them here:

            | Error | Days recurring | Existing issue | Status |
            | --- | --- | --- | --- |
            | Short description | N days | #123 or "none" | open/assigned/untracked |

            Recurring errors that are not yet tracked in an issue should be called out explicitly.

            ## Critical Issues

            For each significant error group (ordered by severity/impact):

            ### Issue N: <Short descriptive title>

            **Error code**: `CODE` | **Occurrences**: N | **Users affected**: N
            **Command**: `command name` | **Type**: System/User
            **Recurring**: Yes (N days) / No | **Existing issue**: #123 or None
            **PostHog**: [View in error tracking](https://us.posthog.com/project/<PROJECT_ID>/error_tracking/<fingerprint>)

            **Error from PostHog**:
            ```
            ErrorType: error message from exception_message
            ```

            **Stack trace** (from PostHog, abbreviated — redact PII from paths):
            ```
            ErrorType: message
                at function (file:line:col)
                at function (file:line:col)
                ...
            ```

            **What happened**:
            One paragraph explaining the error in plain English.

            **Root cause in code**:
            Explain what you found in the source code. Include the relevant code snippet:
            ```typescript
            // src/path/to/file.ts:NN
            <relevant code>
            ```

            **Additional context**:
            - CLI versions: list
            - Platforms: list
            - Internal vs external: N of M occurrences from internal users

            **Expected behavior**: What should have happened
            **Actual behavior**: What actually happened

            ---

            ## Suggestions

            Numbered list of actionable next steps, ordered by priority. For each:
            1. What to fix and where (file path + line)
            2. Suggested approach (brief)
            3. Severity: critical / high / medium / low
            ```

            If there are zero errors worth reporting, do NOT create an issue. Instead just print "No significant errors to report."

            ## Rules

            - Be concise. Don't pad the report.
            - ALWAYS include code snippets from the repo for every error. Read the source files using the stack trace frames, then paste the relevant lines in fenced code blocks with `// src/path:line` comments. This is mandatory — a report without code snippets is incomplete.
            - For stack traces, show the most relevant 3-5 frames, not the full trace.
            - Group duplicate/similar errors together. Don't repeat the same error N times.
            - Add the label "error-report" to the issue.
            - Don't speculate — if you can't find the root cause in the code, say so.
            - When an existing issue already tracks the error, reference it with `#<number>` instead of re-explaining everything. Just note if occurrences have increased or new users are affected.
            - Recurring untracked errors should be flagged prominently — these are being ignored.
          claude_args: '--model claude-sonnet-4-20250514 --allowed-tools Read Glob Grep "Bash(cat /tmp/*)" "Bash(gh issue create:*)" "Bash(gh issue list:*)" "Bash(gh issue view:*)" "Bash(gh label create:*)"'

      - name: No errors summary
        if: steps.check-errors.outputs.has_errors != 'true'
        run: echo "### No errors in the last ${{ steps.time-range.outputs.hours }} hours" >> $GITHUB_STEP_SUMMARY
